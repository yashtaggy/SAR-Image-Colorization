# 🌍 SAR Image Colorization using Deep Learning (SIH1733)

## 📌 Problem Statement
Synthetic Aperture Radar (SAR) imagery is rich in structural and textural information but lacks the intuitive appeal of color, which can provide more comprehensive insights for space-borne applications.  
This project aims to build a **Deep Learning model** that colorizes grayscale SAR images using paired SAR–Optical datasets, enhancing interpretability and usability for applications like geological studies, disaster management, and environmental monitoring.

## 🎯 Objectives
- Develop a **novel DL model (U-Net, Pix2Pix)** for SAR → Optical image colorization.
- Improve SAR data usability with **intuitive visual outputs**.
- Achieve measurable quality using **PSNR, SSIM, Perceptual Loss**.
- Deploy as a **user-friendly software tool** (CLI + Web UI).

## 🏗️ Architecture (High-Level)
1. **Data Preprocessing**  
   - SAR + Optical pairs aligned and tiled (256×256).  
   - Normalization, augmentation.  

2. **Model Development**  
   - Baseline: **U-Net** (supervised).  
   - Advanced: **Pix2Pix GAN** (adversarial training).  

3. **Training & Evaluation**  
   - Losses: L1, SSIM, Perceptual.  
   - Metrics: PSNR, SSIM, visual inspection.  

4. **Deployment**  
   - CLI tool for analysts.  
   - Web app (FastAPI / Streamlit).  

## 🛠️ Tech Stack
- **Language:** Python 3.10+
- **Deep Learning Framework:** PyTorch
- **Data Handling:** GDAL, Rasterio, OpenCV, NumPy, Pandas
- **Experiment Tracking:** Weights & Biases (W&B) / MLflow
- **Deployment:** FastAPI, Streamlit, Docker
- **Version Control:** GitHub + Git LFS / DVC for large files

## 📂 Repo Structure

| Directory/File         | Description                                                          |
|------------------------|----------------------------------------------------------------------|
| `SAR-Colorization/`    | The root directory of the project.                                   |
| ├── `app/`             | Contains code for deployment, including API and UI components.       |
| ├── `checkpoints/`     | Stores saved model checkpoints. This directory is `.gitignore`d.     |
| ├── `configs/`         | Configuration files for training and evaluation.                     |
| ├── `data/`            | Holds preprocessed data. This directory is `.gitignore`d.            |
| ├── `models/`          | Defines the neural network architectures (e.g., U-Net, Pix2Pix).     |
| ├── `notebooks/`       | Jupyter notebooks for experimentation and analysis.                  |
| ├── `reports/`         | Stores evaluation reports and results.                               |
| ├── `scripts/`         | Utility scripts for preprocessing, metrics, and other tasks.         |
| ├── `train.py`         | The main script for training the model.                              |
| ├── `evaluate.py`      | Script for evaluating the trained model.                             |
| ├── `infer.py`         | Script for running inference.                                        |
| ├── `requirements.txt` | Lists the required Python dependencies.                              |
| ├── `LICENSE`          | The project's license file.                                          |
| └── `README.md`        | The main documentation file.                                         |

## 🚀 Getting Started
1. Clone this repo:
   ```bash
   git clone https://github.com/<org>/<repo>.git
   cd SAR-Colorization
   ```

2. Create environment:

   ```bash
   conda create -n sarcolor python=3.10 -y
   conda activate sarcolor
   pip install -r requirements.txt
   ```
3. Run preprocessing:

   ```bash
   python scripts/preprocess.py --input data/raw --output data/tiles
   ```

4. Train model:

   ```bash
   python train.py --config configs/unet.yaml
   ```

5. Run inference:

   ```bash
   python infer.py --ckpt checkpoints/unet_best.pt --input samples/sar.tif --out outputs/colorized.png
   ```
