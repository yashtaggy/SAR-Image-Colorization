# ğŸŒˆ SAR Image Colorization using Deep Learning

> **Transforming Monochromatic SAR Imagery into Intuitive, Colorized Visuals for Enhanced Remote Sensing Analysis**

---

## ğŸ“˜ Project Overview

Synthetic Aperture Radar (**SAR**) imagery provides invaluable structural and textural information about the Earthâ€™s surface, but it lacks the intuitive appeal of color. This project aims to bridge that gap by **colorizing grayscale SAR images using Deep Learning (DL)** models trained on paired **SAR and Optical (Sentinel-1 & Sentinel-2)** data.

By learning the complex mapping between radar backscatter and optical reflectance, this project produces colorized SAR images that significantly enhance the **interpretability and usability of remote sensing data** for applications such as **geological studies, urban mapping, and environmental monitoring**.

---

## ğŸ¯ Objectives

* Develop a **Deep Learning-based SAR image colorization model** for robust image-to-image translation.
* Enhance the **visual interpretability** and information density of SAR imagery.
* Create a **scalable pipeline** for preprocessing, collocating, and preparing Sentinel-1 & Sentinel-2 imagery for training.
* Design a **user-ready colorization software** (future work) for remote sensing analysts.

---

## âš™ï¸ Key Features

âœ… **Data Preprocessing Pipeline:** Robust scripts for processing Sentinel-1 (SAR) and Sentinel-2 (Optical) data.
âœ… **Automatic Co-registration:** Automated co-registration and tiling of paired SAR/Optical data for dataset creation.
âœ… **Custom DL Model:** Implementation of a custom **U-Net** (or **GAN**) for SAR-to-RGB translation.
âœ… **Configurable Training:** Modular training pipeline built with **PyTorch**.
âœ… **Evaluation & Visualization:** Scripts for model evaluation, metrics tracking, and result visualization.
âœ… **Modular Structure:** Clean and reproducible project layout.

---

## ğŸ—‚ï¸ Project Structure

The project is structured for clear separation of concerns, ensuring reproducibility and easy extension:

```yaml
EXPLORER-SAR-IMAGE-COLORIZATION/
â”œâ”€â”€ app/                  # Application code (future GUI or API)
â”œâ”€â”€ checkpoints/          # Model checkpoints during training
â”œâ”€â”€ config/               # Configuration files for data and model parameters
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/                # Original raw Sentinel data
â”‚ â”œâ”€â”€ processed/          # Preprocessed & collocated GeoTIFFs
â”‚ â”œâ”€â”€ tiles/              # Training-ready dataset (SAR + RGB tiles)
â”‚ â”œâ”€â”€ maharashtra.geojson # AOI shapefile
â”‚ â””â”€â”€ collocated_s1_s2.tif# Main dataset (SAR + Optical pairs)
â”œâ”€â”€ models/               # Trained DL models
â”œâ”€â”€ notebooks/            # Jupyter notebooks for experiments and data exploration
â”œâ”€â”€ outputs/              # Predictions, metrics, and visualizations
â”œâ”€â”€ scripts/              # All preprocessing and training scripts
â”‚ â”œâ”€â”€ preprocess_s1.py
â”‚ â”œâ”€â”€ preprocess_s2.py
â”‚ â”œâ”€â”€ coregister_pairs.py
â”‚ â”œâ”€â”€ tile_dataset.py
â”‚ â”œâ”€â”€ inspect_final_geotiff.py
â”‚ â””â”€â”€ train_unet.py       # Main training script
â”œâ”€â”€ venv/                 # Virtual environment (ignored by Git)
â”œâ”€â”€ Dockerfile            # For containerization
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
