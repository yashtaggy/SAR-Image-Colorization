# ğŸŒ SAR Image Colorization using Deep Learning (SIH1733)

## ğŸ“Œ Problem Statement
Synthetic Aperture Radar (SAR) imagery is rich in structural and textural information but lacks the intuitive appeal of color, which can provide more comprehensive insights for space-borne applications.  
This project aims to build a **Deep Learning model** that colorizes grayscale SAR images using paired SARâ€“Optical datasets, enhancing interpretability and usability for applications like geological studies, disaster management, and environmental monitoring.

## ğŸ¯ Objectives
- Develop a **novel DL model (U-Net, Pix2Pix)** for SAR â†’ Optical image colorization.
- Improve SAR data usability with **intuitive visual outputs**.
- Achieve measurable quality using **PSNR, SSIM, Perceptual Loss**.
- Deploy as a **user-friendly software tool** (CLI + Web UI).

## ğŸ—ï¸ Architecture (High-Level)
1. **Data Preprocessing**  
   - SAR + Optical pairs aligned and tiled (256Ã—256).  
   - Normalization, augmentation.  

2. **Model Development**  
   - Baseline: **U-Net** (supervised).  
   - Advanced: **Pix2Pix GAN** (adversarial training).  

3. **Training & Evaluation**  
   - Losses: L1, SSIM, Perceptual.  
   - Metrics: PSNR, SSIM, visual inspection.  

4. **Deployment**  
   - CLI tool for analysts.  
   - Web app (FastAPI / Streamlit).  

## ğŸ› ï¸ Tech Stack
- **Language:** Python 3.10+
- **Deep Learning Framework:** PyTorch
- **Data Handling:** GDAL, Rasterio, OpenCV, NumPy, Pandas
- **Experiment Tracking:** Weights & Biases (W&B) / MLflow
- **Deployment:** FastAPI, Streamlit, Docker
- **Version Control:** GitHub + Git LFS / DVC for large files

## ğŸ“‚ Repo Structure

| Directory/File         | Description                                                          |
|------------------------|----------------------------------------------------------------------|
| `SAR-Colorization/`    | The root directory of the project.                                   |
| â”œâ”€â”€ `app/`             | Contains code for deployment, including API and UI components.       |
| â”œâ”€â”€ `checkpoints/`     | Stores saved model checkpoints. This directory is `.gitignore`d.     |
| â”œâ”€â”€ `configs/`         | Configuration files for training and evaluation.                     |
| â”œâ”€â”€ `data/`            | Holds preprocessed data. This directory is `.gitignore`d.            |
| â”œâ”€â”€ `models/`          | Defines the neural network architectures (e.g., U-Net, Pix2Pix).     |
| â”œâ”€â”€ `notebooks/`       | Jupyter notebooks for experimentation and analysis.                  |
| â”œâ”€â”€ `reports/`         | Stores evaluation reports and results.                               |
| â”œâ”€â”€ `scripts/`         | Utility scripts for preprocessing, metrics, and other tasks.         |
| â”œâ”€â”€ `train.py`         | The main script for training the model.                              |
| â”œâ”€â”€ `evaluate.py`      | Script for evaluating the trained model.                             |
| â”œâ”€â”€ `infer.py`         | Script for running inference.                                        |
| â”œâ”€â”€ `requirements.txt` | Lists the required Python dependencies.                              |
| â”œâ”€â”€ `LICENSE`          | The project's license file.                                          |
| â””â”€â”€ `README.md`        | The main documentation file.                                         |

## ğŸš€ Getting Started
1. Clone this repo:
   ```bash
   git clone https://github.com/<org>/<repo>.git
   cd SAR-Colorization
   ```

2. Create environment:

   ```bash
   conda create -n sarcolor python=3.10 -y
   conda activate sarcolor
   pip install -r requirements.txt
   ```
3. Run preprocessing:

   ```bash
   python scripts/preprocess.py --input data/raw --output data/tiles
   ```

4. Train model:

   ```bash
   python train.py --config configs/unet.yaml
   ```

5. Run inference:

   ```bash
   python infer.py --ckpt checkpoints/unet_best.pt --input samples/sar.tif --out outputs/colorized.png
   ```
